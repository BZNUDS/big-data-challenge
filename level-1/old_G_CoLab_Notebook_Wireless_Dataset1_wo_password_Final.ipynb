{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6pz7LGh_L1p","outputId":"ad49e113-1ffb-4851-ef38-1d9a25033a19"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connecting to security.\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [806 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n","Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,992 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,830 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,021 kB]\n","Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [982 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,515 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,262 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,015 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,290 kB]\n","Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [47.7 kB]\n","Fetched 16.1 MB in 4s (4,472 kB/s)\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.2.1'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwUsRhZOuFGB"},"outputs":[],"source":["!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7zQhOSauFGD"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIGU4Tzs_Q4g"},"outputs":[],"source":["from pyspark import SparkFiles\n","# Load in employee.csv from S3 into a DataFrame\n","url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Wireless_v1_00.tsv.gz\"\n","spark.sparkContext.addFile(url)\n","\n","df = spark.read.option('header', 'true').csv(SparkFiles.get(\"amazon_reviews_us_Wireless_v1_00.tsv.gz\"), inferSchema=True, sep='\\t', timestampFormat=\"mm/dd/yy\")\n","df.show(10)"]},{"cell_type":"markdown","metadata":{"id":"kdtKPZ1w_V3e"},"source":["## Drop duplicates and incomplete rows"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10qoqQv3_Y_w"},"outputs":[],"source":["print(df.count())\n","df = df.dropna()\n","print(df.count())\n","df = df.dropDuplicates()\n","print(df.count())"]},{"cell_type":"markdown","metadata":{"id":"GAgvBYkG_awE"},"source":["## Examine the schema"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXtPi-Hw_dCe"},"outputs":[],"source":["df.printSchema()"]},{"cell_type":"markdown","metadata":{"id":"klopnaUE_eZV"},"source":["## Rename columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9b0dvAat_f7L"},"outputs":[],"source":["# df1 = df.withColumnRenamed(\"Employee ID\", \"employee_id\") \\\n","#         .withColumnRenamed(\"Email\", \"email\") \\\n","#         .withColumnRenamed(\"Gender\", \"gender\") \\\n","#         .withColumnRenamed(\"Hire Date\", \"hire_date\") \\\n","#         .withColumnRenamed(\"DOB\", \"dob\") \\\n","#         .withColumnRenamed(\"Encrypted Password\", \"password\")\n","# df1.show(5)\n","# NOTE: The above code from Homework Lesson 22.3.4 was not needed since all of the columns aligned to what was needed:)\n","df1=df\n","df1"]},{"cell_type":"markdown","metadata":{"id":"AbG7CtSA_gfw"},"source":["## Create a new DataFrame for products "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"saJ1WiZb_ik6"},"outputs":[],"source":["products = df1.select([\"product_id\", \"product_title\"])\n","products.show(5)"]},{"cell_type":"markdown","metadata":{"id":"0PDvBiVN_jGe"},"source":["## Write DataFrame to RDS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fOIS3viE_leJ"},"outputs":[],"source":["# Configuration for RDS instance\n","mode=\"append\"\n","jdbc_url = \"jdbc:postgresql://rdsdb.cgx5vst360bw.us-east-2.rds.amazonaws.com:5432/dbforbigdata\"\n","print(\"Need to change password below as per BZ Gmail email on 6/8/22 at 10:50pm\")\n","print(\"change it from xxxxxxxx to temporary one 1 per BZ Gmail email on 6/8/22 at 10:50pm\")\n","config = {\"user\":\"postgres\",\n","          \"password\": \"tempone1\",\n","          \"driver\":\"org.postgresql.Driver\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6_O84CK_nV5"},"outputs":[],"source":["# Write DataFrame to table\n","\n","products.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"]},{"cell_type":"markdown","source":["## Create a new DataFrame for review_id_table"],"metadata":{"id":"d25Ph5kItUij"}},{"cell_type":"code","source":["review_id_table = df1.select([\"review_id\", \"customer_id\", \"product_id\", \"product_parent\", \"review_date\"])\n","review_id_table.show(10)"],"metadata":{"id":"ksgVNKZZtLq9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Write DataFrame to RDS"],"metadata":{"id":"IkbqTiJQtTZC"}},{"cell_type":"code","source":["# Write DataFrame to review_id_table\n","review_id_table.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"],"metadata":{"id":"mAvuRl-gtMJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create a new DataFrame for customers:"],"metadata":{"id":"FndJDpXNtSa7"}},{"cell_type":"code","source":["# Since customer_count isn't available in the Amazon supplied Datasets, first need to count customer occurences of customer_id, then rename columns, then \n","customers = df1.select([\"customer_id\"])\n","customers.show(10)\n","\n","customers = customers.groupBy(\"customer_id\").count()\n","customers.show(10)\n","\n","customers.orderBy(\"customer_id\").select([\"customer_id\", \"count\"])\n","customers.show(10)\n","\n","customers = customers.withColumnRenamed(\"count\",\"customer_count\")\n","customers.show(10)\n","\n","customers.printSchema()"],"metadata":{"id":"N-oFcYVGtMjk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Write DataFrame to RDS"],"metadata":{"id":"q-xyq7LPtRn6"}},{"cell_type":"code","source":["# Write DataFrame to table\n","customers.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"],"metadata":{"id":"OwDFI__ytM_K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create a new DataFrame for vine_table\n"],"metadata":{"id":"r15ZZvkqtQgi"}},{"cell_type":"code","source":["vine_table = df1.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\"])\n","vine_table.show(10)"],"metadata":{"id":"hzcm1IrKtNVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vine_table.printSchema()"],"metadata":{"id":"WQKnL5K8ANp1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Change 'star_rating', 'helpful_votes', and 'total_votes' \n","## in vine_table to Integer type"],"metadata":{"id":"c0dUW-gD08o3"}},{"cell_type":"code","source":["#from traitlets.traitlets import Integer\n","from pyspark.sql.types import IntegerType\n","## Convert star_rating from string to interger\n","vine_table = vine_table.withColumn(\"star_rating\",vine_table[\"star_rating\"].cast(IntegerType()))\\\n","  .withColumn(\"helpful_votes\",vine_table[\"helpful_votes\"].cast(IntegerType()))\\\n","  .withColumn(\"total_votes\",vine_table[\"total_votes\"].cast(IntegerType()))\n","vine_table.printSchema()"],"metadata":{"id":"cjqY8qgjAdsU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Write DataFrame to RDS"],"metadata":{"id":"XdCUvPnptPYD"}},{"cell_type":"code","source":["# Write DataFrame to table\n","vine_table.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"],"metadata":{"id":"xQ4RSgfJtNqz"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"G_CoLab_Notebook_Wireless_Dataset1_wo_password.ipynb","provenance":[{"file_id":"1GC0J07_niP5lcPgWJ10UO7qaC9nz3jfn","timestamp":1654924291771},{"file_id":"1IUxlCcCk7vM10YqO3NKxH553GLErhP3k","timestamp":1654839457209},{"file_id":"1kZrGnHu1T9APoZLT55LWUtD1ISJUsJun","timestamp":1654839391984}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"nbformat":4,"nbformat_minor":0}